{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos \n",
    "### DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Cargamos los datos\n",
    "valoraciones = pd.read_json('data/web_reviews.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función .info()\n",
    "## El resultado de `valoraciones.info()` es que contiene un total de **10,261 filas** y **9 columnas**.\n",
    "**Columnas:**\n",
    "- **reviewerID**: ID del revisor, tipo `object` (cadena de texto).\n",
    "- **asin**: ID del producto, tipo `object`.\n",
    "- **reviewerName**: Nombre del revisor, tipo `object`.\n",
    "- **helpful**: Información sobre la utilidad de la reseña (como una lista que muestra votos útiles), tipo `object`.\n",
    "- **reviewText**: Texto de la reseña, tipo `object`.\n",
    "- **overall**: Calificación general del producto (1 a 5), tipo `int64`.\n",
    "- **summary**: Resumen breve de la reseña, tipo `object`.\n",
    "- **unixReviewTime**: Fecha de la reseña en formato de tiempo Unix, tipo `int64`.\n",
    "- **reviewTime**: Fecha de la reseña en formato de texto, tipo `object`.\n",
    "\n",
    "### Información adicional:\n",
    "- **Tipos de datos**: La mayoría de las columnas son de tipo `object` (cadenas de texto), excepto `overall` y `unixReviewTime`, que son enteros (`int64`).\n",
    "- **Uso de memoria**: El DataFrame ocupa aproximadamente **721.6 KB** en memoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "       reviewerID        asin  \\\n",
      "0  A2IBPI20UZIR0U  1384719342   \n",
      "1  A14VAT5EAX3D9S  1384719342   \n",
      "2  A195EZSQDW3E21  1384719342   \n",
      "3  A2C00NNG1ZQQG2  1384719342   \n",
      "4   A94QU4C90B1AX  1384719342   \n",
      "\n",
      "                                       reviewerName   helpful  \\\n",
      "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
      "1                                              Jake  [13, 14]   \n",
      "2                      Rick Bennette \"Rick Bennette    [1, 1]   \n",
      "3                          RustyBill \"Sunday Rocker    [0, 0]   \n",
      "4                                     SEAN MASLANKA    [0, 0]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  Not much to write about here, but it does exac...        5   \n",
      "1  The product does exactly as it should and is q...        5   \n",
      "2  The primary job of this device is to block the...        5   \n",
      "3  Nice windscreen protects my MXL mic and preven...        5   \n",
      "4  This pop filter is great. It looks and perform...        5   \n",
      "\n",
      "                                 summary  unixReviewTime   reviewTime  \\\n",
      "0                                   good      1393545600  02 28, 2014   \n",
      "1                                   Jake      1363392000  03 16, 2013   \n",
      "2                   It Does The Job Well      1377648000  08 28, 2013   \n",
      "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014   \n",
      "4  No more pops when I record my vocals.      1392940800  02 21, 2014   \n",
      "\n",
      "  instrumentType  \n",
      "0         String  \n",
      "1       Keyboard  \n",
      "2     Wind Brass  \n",
      "3                 \n",
      "4       Keyboard  \n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10261 entries, 0 to 10260\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   reviewerID      10261 non-null  object\n",
      " 1   asin            10261 non-null  object\n",
      " 2   reviewerName    10261 non-null  object\n",
      " 3   helpful         10261 non-null  object\n",
      " 4   reviewText      10261 non-null  object\n",
      " 5   overall         10261 non-null  int64 \n",
      " 6   summary         10261 non-null  object\n",
      " 7   unixReviewTime  10261 non-null  int64 \n",
      " 8   reviewTime      10261 non-null  object\n",
      " 9   instrumentType  10261 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 801.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos las primeras filas del dataset\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(valoraciones.head())\n",
    "\n",
    "# Revisamos la estructura de las columnas y el tipo de datos\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(valoraciones.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .describe\n",
    "El resultado de `valoraciones.describe()` proporciona un resumen estadístico de las columnas **numéricas** en el DataFrame. Ayudan a entender la distribución y la tendencia de las calificaciones junto con los tiempos de revisión:\n",
    "\n",
    "### Interpretación:\n",
    "- **overall**: \n",
    "  - Representa la calificación general del producto.\n",
    "  - La media es de **4.59**, lo cual indica que la mayoría de las valoraciones son altas.\n",
    "  - El valor mínimo es **1** y el máximo es **10**.\n",
    "  \n",
    "- **unixReviewTime**: \n",
    "  - Representa la fecha de la reseña en formato Unix.\n",
    "  - La media es **1.356565e+09**, y el rango va desde **1.204819e+09** hasta **1.405382e+09**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10261.000000</td>\n",
       "      <td>1.026100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.499659</td>\n",
       "      <td>1.360606e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.415221</td>\n",
       "      <td>3.779735e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.095466e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.343434e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.368490e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.388966e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.405987e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall  unixReviewTime\n",
       "count  10261.000000    1.026100e+04\n",
       "mean       4.499659    1.360606e+09\n",
       "std        1.415221    3.779735e+07\n",
       "min        0.000000    1.095466e+09\n",
       "25%        4.000000    1.343434e+09\n",
       "50%        5.000000    1.368490e+09\n",
       "75%        5.000000    1.388966e+09\n",
       "max       10.000000    1.405987e+09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos estadísticas descriptivas para la columna 'overall'\n",
    "print(\"\\nEstadísticas descriptivas de la calificación 'overall':\")\n",
    "print(valoraciones['overall'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de calificaciones (overall):\n",
      "overall\n",
      "5     6595\n",
      "4     1981\n",
      "3      730\n",
      "0      273\n",
      "2      240\n",
      "10     240\n",
      "1      202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Longitud promedio de las reseñas:\n",
      "485.9287593801774\n"
     ]
    }
   ],
   "source": [
    "# Revisión de valores únicos y su distribución en 'overall'\n",
    "print(\"\\nDistribución de calificaciones (overall):\")\n",
    "print(valoraciones['overall'].value_counts())\n",
    "\n",
    "# Análisis de la longitud de los textos en 'reviewText' para entender el contenido\n",
    "valoraciones['review_length'] = valoraciones['reviewText'].apply(len)\n",
    "print(\"\\nLongitud promedio de las reseñas:\")\n",
    "print(valoraciones['review_length'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos un modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precisión del modelo: 0.65\n",
      "Error absoluto medio (MAE): 0.74\n"
     ]
    }
   ],
   "source": [
    "# Separar características y la variable objetivo\n",
    "X = valoraciones['reviewText']\n",
    "y = valoraciones['overall']\n",
    "\n",
    "# Vectorización de los textos con TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limitamos el número de características para simplificar\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nPrecisión del modelo: {accuracy:.2f}\")\n",
    "print(f\"Error absoluto medio (MAE): {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscar missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes por columna:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Defino una función que me ayude a comparar las diferentes estrategias.\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    ''' \n",
    "    Función para comparar estrategias y devolver el MAE \n",
    "    '''\n",
    "    model = RandomForestRegressor(n_estimators=73, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "# Contamos los valores faltantes en cada columna\n",
    "missing_values = valoraciones.isnull().sum()\n",
    "\n",
    "# Filtramos solo las columnas que tienen valores faltantes\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Identificar columnas con valores faltantes\n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "# ************************************************** NO SE PUEDEN ELIMINAR LAS MISSING VALUES PORQUE NO HAY *******************************************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de Tratamiento de Valores Faltantes y Preparación de Datos\n",
    "\n",
    "En este documento se detallan las técnicas utilizadas para tratar valores faltantes y preparar los datos para el modelado. Cada técnica tiene sus propias ventajas y limitaciones, y la selección de cada una depende del contexto y las características de los datos.\n",
    "\n",
    "## 1. Imputación Básica con la Media\n",
    "La **imputación básica con la media** consiste en reemplazar los valores faltantes de cada columna por la media de esa columna. Este método es útil cuando los valores están distribuidos simétricamente, ya que la media representa el \"centro\" de la distribución de datos.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Sencillo de implementar.\n",
    "- Mantiene el tamaño del conjunto de datos.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Puede sesgar los resultados si hay valores extremos.\n",
    "- No conserva la variabilidad en los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (imputación con media):\n",
      "0.9354842117671656\n"
     ]
    }
   ],
   "source": [
    "# Imputación básica con la media\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputación básica (media) como referencia\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(imputer.transform(X_test))\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_test.columns\n",
    "\n",
    "print(\"MAE (imputación con media):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imputación con Extensión Utilizando la Media\n",
    "La **imputación con extensión** consiste en crear indicadores adicionales que registran si un valor era originalmente faltante. Luego, se imputa el valor faltante usando la media, lo que ayuda a conservar la información sobre los datos faltantes y permite al modelo \"saber\" que se ha realizado una imputación.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Conserva información sobre la ausencia de datos.\n",
    "- Puede mejorar el rendimiento del modelo si los datos faltantes siguen un patrón.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Aumenta el número de características en el conjunto de datos.\n",
    "- Puede agregar complejidad innecesaria si los valores faltantes son aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (imputación con extensión y media):\n",
      "0.9354842117671656\n"
     ]
    }
   ],
   "source": [
    "# Imputación con extensión utilizando la media\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_test.copy()\n",
    "\n",
    "# Añadir indicadores de valores faltantes\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Imputar la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid = pd.DataFrame(imputer.transform(X_valid_plus))\n",
    "imputed_X_train.columns = X_train_plus.columns\n",
    "imputed_X_valid.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE (imputación con extensión y media):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imputación con Extensión Utilizando la Mediana\n",
    "La **imputación con extensión utilizando la mediana** es similar al método anterior, pero reemplaza los valores faltantes por la mediana de cada columna en lugar de la media. Es útil cuando los datos tienen una distribución sesgada o contienen valores atípicos, ya que la mediana es menos sensible a los valores extremos.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Reduce el sesgo causado por valores atípicos.\n",
    "- Mantiene la robustez en presencia de distribuciones sesgadas.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Puede no capturar bien la media si los datos están distribuidos simétricamente.\n",
    "- Al igual que la media, puede reducir la variabilidad original de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (imputación con extensión y mediana):\n",
      "0.9354842117671656\n"
     ]
    }
   ],
   "source": [
    "# Imputación con extensión utilizando la mediana\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_test.copy()\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid = pd.DataFrame(imputer.transform(X_valid_plus))\n",
    "imputed_X_train.columns = X_train_plus.columns\n",
    "imputed_X_valid.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE (imputación con extensión y mediana):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Imputación con Extensión Utilizando la Moda\n",
    "La **imputación con extensión utilizando la moda** reemplaza los valores faltantes por el valor más frecuente (o moda) de cada columna. Este método es especialmente útil para datos categóricos, donde la moda representa el valor que ocurre con mayor frecuencia.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Muy útil para datos categóricos.\n",
    "- Mantiene la distribución de valores en columnas con poca variabilidad.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Puede introducir sesgo si la moda no representa bien los valores faltantes.\n",
    "- Menos adecuado para datos numéricos continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (imputación con extensión y moda):\n",
      "0.9354842117671656\n"
     ]
    }
   ],
   "source": [
    "# Imputación con extensión utilizando la moda\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_test.copy()\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid = pd.DataFrame(imputer.transform(X_valid_plus))\n",
    "imputed_X_train.columns = X_train_plus.columns\n",
    "imputed_X_valid.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE (imputación con extensión y moda):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Imputación con Extensión Utilizando un Valor Constante\n",
    "La **imputación con un valor constante** es una técnica donde se reemplazan los valores faltantes con un valor específico (por ejemplo, `0` o `-1`). Este método es útil cuando se desea marcar valores faltantes con un indicador específico o cuando el contexto permite asignar un valor neutro o común.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Proporciona flexibilidad para seleccionar el valor de imputación.\n",
    "- Útil para valores categóricos o cuando el valor faltante tiene un significado específico.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Puede no ser adecuado si el valor constante no tiene sentido en el contexto de los datos.\n",
    "- Puede afectar negativamente el rendimiento del modelo si el valor elegido introduce ruido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (imputación con extensión y valor constante):\n",
      "0.9354842117671656\n"
     ]
    }
   ],
   "source": [
    "# Imputación con extensión utilizando un valor constante\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_test.copy()\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid = pd.DataFrame(imputer.transform(X_valid_plus))\n",
    "imputed_X_train.columns = X_train_plus.columns\n",
    "imputed_X_valid.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE (imputación con extensión y valor constante):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Eliminación de Columnas con Valores Faltantes\n",
    "La **eliminación de columnas con valores faltantes** consiste en eliminar cualquier columna que contenga valores faltantes. Es una técnica útil si hay pocas columnas con valores faltantes o si las columnas no son esenciales para el modelo.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Sencilla de implementar y asegura que no haya datos faltantes en el conjunto final.\n",
    "- Puede mejorar la eficiencia al reducir el número de características.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Puede resultar en la pérdida de información importante si las columnas eliminadas son relevantes.\n",
    "- No es adecuado si muchas columnas contienen valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (eliminar columnas):\n",
      "0.9354842117671656\n"
     ]
    }
   ],
   "source": [
    "# Selecciono las columnas con valores faltantes en el conjunto de entrenamiento.\n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "# Elimino las columnas de los datos de entrenamiento y validación.\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "# Calculo el MAE usando el conjunto de datos con columnas eliminadas.\n",
    "print(\"MAE (eliminar columnas):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen Preproceso de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (imputación con media):\n",
      "0.9354842117671656\n",
      "MAE (imputación con extensión y media):\n",
      "0.9354842117671656\n",
      "MAE (imputación con extensión y mediana):\n",
      "0.9354842117671656\n",
      "MAE (imputación con extensión y moda):\n",
      "0.9354842117671656\n",
      "MAE (imputación con extensión y valor constante):\n",
      "0.9354842117671656\n",
      "MAE (eliminar columnas):\n",
      "0.9354842117671656\n"
     ]
    }
   ],
   "source": [
    "# Inputacion utilizando la media\n",
    "print(\"MAE (imputación con media):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))\n",
    "\n",
    "# Inputacion con extensión utilizando la media\n",
    "print(\"MAE (imputación con extensión y media):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))\n",
    "\n",
    "# Inputacion con extensión utilizando la mediana \n",
    "print(\"MAE (imputación con extensión y mediana):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))\n",
    "\n",
    "# Imputacion con extension utilizando la moda \n",
    "print(\"MAE (imputación con extensión y moda):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))\n",
    "\n",
    "# Calculo el MAE usando un valor constante\n",
    "print(\"MAE (imputación con extensión y valor constante):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_test))\n",
    "\n",
    "# Calculo el MAE usando el conjunto de datos con columnas eliminadas.\n",
    "print(\"MAE (eliminar columnas):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Técnicas de Transformación de Variables Categóricas\n",
    "\n",
    "Al preparar datos para un modelo de machine learning, es importante transformar las variables categóricas en un formato numérico adecuado. A continuación, se describen tres técnicas comunes para trabajar con variables categóricas.\n",
    "\n",
    "## Eliminación de Variables Categóricas\n",
    "\n",
    "La **eliminación de variables categóricas** consiste en descartar aquellas columnas categóricas que no son necesarias o que pueden introducir ruido en el modelo. Esta técnica es útil cuando ciertas variables categóricas no aportan información significativa o cuando el conjunto de datos tiene demasiadas categorías, lo que complica el proceso de codificación.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Sencillo de implementar, ya que solo requiere eliminar columnas.\n",
    "- Reduce la dimensionalidad del conjunto de datos, mejorando la eficiencia.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Puede perderse información valiosa si las variables eliminadas son relevantes.\n",
    "- No adecuado si se pierden variables importantes para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo tras eliminar variables categóricas: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos solo las columnas numéricas y eliminamos variables categóricas\n",
    "X_numerico = valoraciones.select_dtypes(exclude=['object'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_numerico, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Entrenamos un modelo de Random Forest usando solo variables numéricas\n",
    "modelo_rf = RandomForestClassifier(random_state=1)\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "accuracy = modelo_rf.score(X_test, y_test)\n",
    "print(f'Precisión del modelo tras eliminar variables categóricas: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificación Ordinal (Ordinal Encoding)\n",
    "\n",
    "La **codificación ordinal** asigna un valor numérico a cada categoría en una columna, siguiendo un orden. Este método es adecuado para variables categóricas que tienen un orden inherente, como \"Bajo\", \"Medio\" y \"Alto\". Con este enfoque, se asignan valores enteros a cada nivel de la categoría en orden creciente o decreciente.\n",
    "**Ventajas**:\n",
    "\n",
    "- Mantiene el orden natural de las categorías, lo que es importante para variables ordinales.\n",
    "- Sencillo de implementar y no aumenta la dimensionalidad del conjunto de datos.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- No es adecuado para variables categóricas sin un orden específico, ya que introduce relaciones numéricas que no existen.\n",
    "- Puede causar problemas si el modelo interpreta los valores numéricos como cantidades en lugar de categorías.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con codificación ordinal: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Seleccionamos las columnas categóricas\n",
    "categoricas = valoraciones.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Codificamos las columnas categóricas ordinales\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "categoricas_encoded = pd.DataFrame(ordinal_encoder.fit_transform(categoricas), columns=categoricas.columns)\n",
    "\n",
    "# Combinamos las columnas numéricas y las codificadas ordinalmente\n",
    "X_ordinal = pd.concat([X_numerico.reset_index(drop=True), categoricas_encoded], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ordinal, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "accuracy = modelo_rf.score(X_test, y_test)\n",
    "print(f'Precisión del modelo con codificación ordinal: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación One-Hot (One-Hot Encoding)\n",
    "\n",
    "La **codificación one-hot** convierte cada categoría en una columna binaria, donde se indica la presencia o ausencia de cada categoría con valores de `1` o `0`. Este método es adecuado para variables categóricas sin orden, como \"Rojo\", \"Verde\" y \"Azul\", ya que evita introducir relaciones numéricas entre categorías.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Evita introducir relaciones numéricas no deseadas en las variables categóricas sin orden.\n",
    "- Facilita la interpretación del modelo cuando cada categoría tiene su propia columna.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Aumenta la dimensionalidad del conjunto de datos, especialmente cuando hay muchas categorías, lo que puede ralentizar el proceso de entrenamiento.\n",
    "- Puede requerir mucho almacenamiento y procesamiento, especialmente para variables con un gran número de categorías.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con codificación One-Hot: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Inicializamos el codificador One-Hot y aplicamos la codificación\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "categoricas_one_hot = one_hot_encoder.fit_transform(categoricas)\n",
    "\n",
    "# Convertimos el resultado en un DataFrame con nombres de columnas\n",
    "categoricas_one_hot_df = pd.DataFrame(categoricas_one_hot, columns=one_hot_encoder.get_feature_names_out(categoricas.columns))\n",
    "\n",
    "# Combinamos las columnas numéricas y las codificadas con One-Hot\n",
    "X_one_hot = pd.concat([X_numerico.reset_index(drop=True), categoricas_one_hot_df.reset_index(drop=True)], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_one_hot, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "modelo_rf = RandomForestClassifier(random_state=1)\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "accuracy = modelo_rf.score(X_test, y_test)\n",
    "print(f'Precisión del modelo con codificación One-Hot: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "métodos IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TODO_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
