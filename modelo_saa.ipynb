{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMPEZAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza correctamente técnicas avanzadas de NLP (tokenización, stopwords, stemming/lemmatización, extracción de polaridad, etc.). \n",
    "Explica y justifica el uso de cada técnica y evalúa su impacto en el análisis de sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aneja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aneja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aneja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aneja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aneja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# DESCOMENTAR LA SIGUIENTE LÍNEA PARA DESCARGAR LOS RECURSOS NECESARIOS LA PRIMERA VEZ\n",
    "# nltk.download()\n",
    "# Descargar recursos\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Inicialización de herramientas\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def preprocesar_texto(texto):\n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(texto.lower())\n",
    "    \n",
    "    # Eliminación de stopwords\n",
    "    tokens_sin_stopwords = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    \n",
    "    # Lematización\n",
    "    tokens_lemmatized = [lemmatizer.lemmatize(word) for word in tokens_sin_stopwords]\n",
    "    \n",
    "    return \" \".join(tokens_lemmatized)\n",
    "\n",
    "def analizar_sentimiento(texto, calificacion):\n",
    "    # Análisis de sentimiento del texto con VADER\n",
    "    puntajes = sia.polarity_scores(texto)\n",
    "    sentimiento_texto = 'neutral'  # Valor predeterminado\n",
    "    if puntajes['compound'] >= 0.05:\n",
    "        sentimiento_texto = 'positiva'\n",
    "    elif puntajes['compound'] <= -0.05:\n",
    "        sentimiento_texto = 'negativa'\n",
    "\n",
    "    # Análisis de sentimiento basado en la calificación\n",
    "    if calificacion in [4, 5]:\n",
    "        sentimiento_calificacion = 'positiva'\n",
    "    elif calificacion == 3:\n",
    "        sentimiento_calificacion = 'neutral'\n",
    "    else:\n",
    "        sentimiento_calificacion = 'negativa'\n",
    "\n",
    "    # Combinar ambos análisis de sentimientos\n",
    "    if sentimiento_texto == sentimiento_calificacion:\n",
    "        return sentimiento_texto\n",
    "    else:\n",
    "        return sentimiento_texto  # Priorizar el sentimiento del texto\n",
    "\n",
    "def procesar_datos(df):\n",
    "    # Aplicar preprocesamiento y análisis de sentimientos a cada reseña\n",
    "    df['processed_text'] = df['reviewText'].apply(preprocesar_texto)\n",
    "    df['sentimientos'] = df.apply(lambda row: analizar_sentimiento(row['processed_text'], row['overall']), axis=1)\n",
    "    # Transformar 'reviewTime' a un formato numérico (podemos usar solo el año para simplicidad)\n",
    "    df['reviewYear'] = pd.to_datetime(df['reviewTime']).dt.year\n",
    "    return df\n",
    "\n",
    "# Ejemplo de uso con el DataFrame\n",
    "df = pd.read_json(\"data/web_reviews.json\")\n",
    "df = procesar_datos(df)\n",
    "\n",
    "# Vectorización del texto\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Convertir texto en representación numérica\n",
    "X_text = vectorizer.fit_transform(df['processed_text']).toarray()\n",
    "\n",
    "# Concatenar texto vectorizado con otras columnas numéricas\n",
    "X_otro = df[['overall', 'reviewYear']].values\n",
    "\n",
    "X = np.hstack([X_text, X_otro])  # Combinar texto y características numéricas\n",
    "\n",
    "y = df['sentimientos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO 1 --> RandomForestClassifier \n",
    "\n",
    "# ESPECIFICAR QUE PASA SIN TOCAR LOS HIPERPARAMETROS Y TOCANDOLOS EDITANDO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo: 0.8962493911349245\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negativa       1.00      0.02      0.04       159\n",
      "     neutral       0.20      0.02      0.03        54\n",
      "    positiva       0.90      1.00      0.95      1840\n",
      "\n",
      "    accuracy                           0.90      2053\n",
      "   macro avg       0.70      0.35      0.34      2053\n",
      "weighted avg       0.89      0.90      0.85      2053\n",
      "\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy del modelo con los mejores hiperparámetros: 0.8972235752557234\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negativa       1.00      0.02      0.04       159\n",
      "     neutral       0.33      0.02      0.04        54\n",
      "    positiva       0.90      1.00      0.95      1840\n",
      "\n",
      "    accuracy                           0.90      2053\n",
      "   macro avg       0.74      0.35      0.34      2053\n",
      "weighted avg       0.89      0.90      0.85      2053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar y evaluar RandomForestClassifier\n",
    "modelo_RFC_sh = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_RFC_sh.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_RFC_sh = modelo_RFC_sh.predict(X_test)\n",
    "\n",
    "print(\"Accuracy del modelo:\", accuracy_score(y_test, y_pred_RFC_sh))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_RFC_sh))\n",
    "\n",
    "# --------------------------CON HIPERPARAMETROS --------------------------------------------\n",
    "\n",
    "\n",
    "# Definir el modelo base\n",
    "modelo_RFC = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir el rango de hiperparámetros para la búsqueda\n",
    "param_grid_rfc = {\n",
    "    'n_estimators': [50, 100, 200],               # Número de árboles\n",
    "    'max_depth': [None, 10, 20, 30],               # Profundidad máxima del árbol\n",
    "    'min_samples_split': [2, 5, 10]             # Mínimo número de muestras para dividir un nodo\n",
    "}\n",
    "\n",
    "# Usar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=modelo_RFC, param_grid=param_grid_rfc, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Ajustar el modelo con la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros encontrados\n",
    "modelo_RFC_mejorado = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_RFC = modelo_RFC_mejorado.predict(X_test)\n",
    "\n",
    "print(\"Accuracy del modelo con los mejores hiperparámetros:\", accuracy_score(y_test, y_pred_RFC))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO 2 --> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo SVC: 0.8977106673161227\n",
      "\n",
      "Reporte de clasificación (SVC):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negativa       1.00      0.02      0.04       159\n",
      "     neutral       0.00      0.00      0.00        54\n",
      "    positiva       0.90      1.00      0.95      1840\n",
      "\n",
      "    accuracy                           0.90      2053\n",
      "   macro avg       0.63      0.34      0.33      2053\n",
      "weighted avg       0.88      0.90      0.85      2053\n",
      "\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros SVC: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy del modelo SVC con mejores hiperparámetros: 0.8981977593765221\n",
      "\n",
      "Reporte de clasificación (SVC):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negativa       0.80      0.03      0.05       159\n",
      "     neutral       0.00      0.00      0.00        54\n",
      "    positiva       0.90      1.00      0.95      1840\n",
      "\n",
      "    accuracy                           0.90      2053\n",
      "   macro avg       0.57      0.34      0.33      2053\n",
      "weighted avg       0.87      0.90      0.85      2053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar y evaluar SVC\n",
    "modelo_SVC_sh = SVC(kernel='linear', random_state=42)  # Usamos un kernel lineal\n",
    "modelo_SVC_sh.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_svc_sh = modelo_SVC_sh.predict(X_test)\n",
    "\n",
    "print(\"Accuracy del modelo SVC:\", accuracy_score(y_test, y_pred_svc_sh))\n",
    "print(\"\\nReporte de clasificación (SVC):\\n\", classification_report(y_test, y_pred_svc_sh))\n",
    "\n",
    "\n",
    "# --------------------------CON HIPERPARAMETROS --------------------------------------------\n",
    "\n",
    "# Definir el modelo base\n",
    "modelo_SVC = SVC(random_state=42)\n",
    "\n",
    "# Definir el rango de hiperparámetros para la búsqueda\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],            # Penalización por error\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],  # Tipos de kernel\n",
    "    'gamma': ['scale', 'auto'],  # Función de kernel para SVM no lineales\n",
    "}\n",
    "\n",
    "# Usar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search_svc = GridSearchCV(estimator=modelo_SVC, param_grid=param_grid_svc, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Ajustar el modelo con la búsqueda de hiperparámetros\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(f\"Mejores hiperparámetros SVC: {grid_search_svc.best_params_}\")\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros encontrados\n",
    "modelo_SVC_mejorado = grid_search_svc.best_estimator_\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_svc = modelo_SVC_mejorado.predict(X_test)\n",
    "\n",
    "print(\"Accuracy del modelo SVC con mejores hiperparámetros:\", accuracy_score(y_test, y_pred_svc))\n",
    "print(\"\\nReporte de clasificación (SVC):\\n\", classification_report(y_test, y_pred_svc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO 3 --> LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo Logistic Regression: 0.8996590355577204\n",
      "\n",
      "Reporte de clasificación (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negativa       0.64      0.09      0.15       159\n",
      "     neutral       0.00      0.00      0.00        54\n",
      "    positiva       0.90      1.00      0.95      1840\n",
      "\n",
      "    accuracy                           0.90      2053\n",
      "   macro avg       0.51      0.36      0.37      2053\n",
      "weighted avg       0.86      0.90      0.86      2053\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Mejores hiperparámetros Logistic Regression: {'C': 10}\n",
      "Accuracy del modelo Logistic Regression con mejores hiperparámetros: 0.896736483195324\n",
      "\n",
      "Reporte de clasificación (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negativa       0.47      0.23      0.31       159\n",
      "     neutral       0.37      0.13      0.19        54\n",
      "    positiva       0.92      0.98      0.95      1840\n",
      "\n",
      "    accuracy                           0.90      2053\n",
      "   macro avg       0.59      0.45      0.48      2053\n",
      "weighted avg       0.87      0.90      0.88      2053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar y evaluar Logistic Regression\n",
    "modelo_LR_sh = LogisticRegression(max_iter=1000, random_state=42)\n",
    "modelo_LR_sh.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_lr_sh = modelo_LR_sh.predict(X_test)\n",
    "\n",
    "print(\"Accuracy del modelo Logistic Regression:\", accuracy_score(y_test, y_pred_lr_sh))\n",
    "print(\"\\nReporte de clasificación (Logistic Regression):\\n\", classification_report(y_test, y_pred_lr_sh))\n",
    "\n",
    "# --------------------------CON HIPERPARAMETROS --------------------------------------------\n",
    "\n",
    "\n",
    "# Definir el modelo base\n",
    "modelo_LR = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Definir el rango de hiperparámetros para la búsqueda\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10]               # Parámetro de regularización\n",
    "}\n",
    "\n",
    "# Usar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search_lr = GridSearchCV(estimator=modelo_LR, param_grid=param_grid_lr, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Ajustar el modelo con la búsqueda de hiperparámetros\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(f\"Mejores hiperparámetros Logistic Regression: {grid_search_lr.best_params_}\")\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros encontrados\n",
    "modelo_LR_mejorado = grid_search_lr.best_estimator_\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_lr = modelo_LR_mejorado.predict(X_test)\n",
    "\n",
    "print(\"Accuracy del modelo Logistic Regression con mejores hiperparámetros:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nReporte de clasificación (Logistic Regression):\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecciona la mejor estrategia considerando el contexto del dato (imputación con media, mediana, moda, o eliminación). Justifica claramente la decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación variables categoricas \n",
    "# Seleccionamos solo las columnas numéricas y eliminamos variables categóricas\n",
    "X_numerico = df.select_dtypes(exclude=['object'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_numerico, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Entrenamos un modelo de Random Forest usando solo variables numéricas\n",
    "modelo_rf = RandomForestClassifier(random_state=1)\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "accuracy = modelo_rf.score(X_test, y_test)\n",
    "print(f'Precisión del modelo tras eliminar variables categóricas: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Seleccionamos las columnas categóricas\n",
    "categoricas = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Codificamos las columnas categóricas ordinales\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "categoricas_encoded = pd.DataFrame(ordinal_encoder.fit_transform(categoricas), columns=categoricas.columns)\n",
    "\n",
    "# Combinamos las columnas numéricas y las codificadas ordinalmente\n",
    "X_ordinal = pd.concat([X_numerico.reset_index(drop=True), categoricas_encoded], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ordinal, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "accuracy = modelo_rf.score(X_test, y_test)\n",
    "print(f'Precisión del modelo con codificación ordinal: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando modelo Logistic Regression con imputación mean...\n",
      "Accuracy: 0.8962493911349245\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativa       0.00      0.00      0.00       159\n",
      "     neutral       0.00      0.00      0.00        54\n",
      "    positiva       0.90      1.00      0.95      1840\n",
      "\n",
      "    accuracy                           0.90      2053\n",
      "   macro avg       0.30      0.33      0.32      2053\n",
      "weighted avg       0.80      0.90      0.85      2053\n",
      "\n",
      "\n",
      "Evaluando modelo SVC con imputación mean...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\IA+BD\\envs\\5073\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluar_modelos_con_estrategias(df, modelos, estrategias, columna_objetivo='sentimientos'):\n",
    "    \"\"\"\n",
    "    Evalúa modelos con distintas estrategias de imputación o eliminación de valores faltantes.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: El DataFrame con los datos a evaluar.\n",
    "    - modelos: Un diccionario con modelos preentrenados. Ejemplo {'modelo_LR': modelo_LR, 'modelo_SVC': modelo_SVC, ...}\n",
    "    - estrategias: Una lista de las estrategias de imputación a probar. Ejemplo ['mean', 'median', 'most_frequent', 'eliminar'].\n",
    "    - columna_objetivo: Nombre de la columna objetivo.\n",
    "\n",
    "    Returns:\n",
    "    - resultados: Diccionario con los resultados de cada modelo y cada estrategia.\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "\n",
    "    # Filtrar solo columnas numéricas, excluyendo la columna objetivo\n",
    "    columnas_numericas = df.select_dtypes(include=['number']).columns\n",
    "    columnas_numericas = [col for col in columnas_numericas if col != columna_objetivo]\n",
    "\n",
    "    # Iterar por cada estrategia\n",
    "    for estrategia in estrategias:\n",
    "        if estrategia == 'eliminar':\n",
    "            # Si la estrategia es eliminar, eliminamos las filas con valores faltantes en la columna objetivo\n",
    "            df_imputado = df.dropna(subset=[columna_objetivo] + list(columnas_numericas))\n",
    "        else:\n",
    "            # Imputar con la estrategia seleccionada (solo en las columnas numéricas)\n",
    "            imputer = SimpleImputer(strategy=estrategia)\n",
    "            df_imputado = df.copy()\n",
    "\n",
    "            # Aplicamos la imputación a las columnas numéricas\n",
    "            df_imputado[columnas_numericas] = imputer.fit_transform(df_imputado[columnas_numericas])\n",
    "\n",
    "        # Separar las características (X) y la variable objetivo (y)\n",
    "        X = df_imputado[columnas_numericas]  # Excluir columna objetivo\n",
    "        y = df_imputado[columna_objetivo]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Evaluar cada modelo con los datos imputados\n",
    "        for nombre_modelo, modelo in modelos.items():\n",
    "            print(f\"\\nEvaluando modelo {nombre_modelo} con imputación {estrategia}...\")\n",
    "            \n",
    "            # Ajustar el modelo con los datos de entrenamiento\n",
    "            modelo.fit(X_train, y_train)\n",
    "            \n",
    "            # Realizar predicciones\n",
    "            y_pred = modelo.predict(X_test)\n",
    "            \n",
    "            # Evaluar rendimiento\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            clasif_report = classification_report(y_test, y_pred)\n",
    "            \n",
    "            # Almacenar los resultados\n",
    "            if nombre_modelo not in resultados:\n",
    "                resultados[nombre_modelo] = {}\n",
    "            if estrategia not in resultados[nombre_modelo]:\n",
    "                resultados[nombre_modelo][estrategia] = {'accuracy': accuracy, 'classification_report': clasif_report}\n",
    "            \n",
    "            # Imprimir resultados\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Reporte de clasificación:\\n{clasif_report}\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Ejemplo de cómo usar la función con tus modelos creados:\n",
    "\n",
    "# Crear un diccionario con los modelos (asegúrate de tener modelos entrenados)\n",
    "modelos = {\n",
    "    'Logistic Regression': modelo_LR_mejorado,\n",
    "    'SVC': modelo_SVC_mejorado,\n",
    "    'Random Forest': modelo_RFC_mejorado\n",
    "}\n",
    "\n",
    "# Cargar el DataFrame (suponiendo que tienes un DataFrame 'df' con valores faltantes)\n",
    "# df = pd.read_csv(\"ruta_del_archivo.csv\")\n",
    "\n",
    "# Definir las estrategias de imputación a probar\n",
    "estrategias = ['mean', 'median', 'most_frequent', 'eliminar']\n",
    "\n",
    "# Llamar a la función para evaluar los modelos con las diferentes estrategias de imputación\n",
    "resultados = evaluar_modelos_con_estrategias(df, modelos, estrategias)\n",
    "\n",
    "# Mostrar los resultados finales\n",
    "print(\"\\nResumen de resultados:\")\n",
    "for modelo, estrategias_resultados in resultados.items():\n",
    "    print(f\"\\nModelo: {modelo}\")\n",
    "    for estrategia, resultado in estrategias_resultados.items():\n",
    "        print(f\"  Estrategia: {estrategia}\")\n",
    "        print(f\"    Accuracy: {resultado['accuracy']}\")\n",
    "        print(f\"    Reporte de clasificación:\\n{resultado['classification_report']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5073",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
